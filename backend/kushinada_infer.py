"""
Kushinada Hubert Large ã‚’ä½¿ç”¨ã—ãŸæ„Ÿæƒ…åˆ†é¡æ¨è«–ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
4æ„Ÿæƒ…ï¼ˆä¸­ç«‹ãƒ»å–œã³ãƒ»æ€’ã‚Šãƒ»æ‚²ã—ã¿ï¼‰ã®åˆ†é¡ã‚’è¡Œã†
"""

import torch
import os
import logging
import soundfile as sf
import tarfile
import tempfile
import shutil
from typing import Tuple
from transformers import HubertModel, AutoFeatureExtractor

logger = logging.getLogger(__name__)

def download_model_from_r2():
    """R2ã‹ã‚‰Kushinadaãƒ¢ãƒ‡ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¦è§£å‡"""
    from config import settings
    from services.storage_service import StorageService
    
    try:
        logger.info("ğŸ“¥ R2ã‹ã‚‰Kushinadaãƒ¢ãƒ‡ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ä¸­...")
        
        # ãƒ­ãƒ¼ã‚«ãƒ«ãƒ‘ã‚¹ã®ç¢ºèªï¼ˆFly.io Volumesã§ã®æ°¸ç¶šåŒ–å¯¾å¿œï¼‰
        local_model_path = settings.KUSHINADA_LOCAL_PATH
        if os.path.exists(local_model_path) and os.path.exists(os.path.join(local_model_path, "config.json")):
            logger.info(f"âœ… ãƒ¢ãƒ‡ãƒ«ã¯æ—¢ã«ãƒ­ãƒ¼ã‚«ãƒ«ã«å­˜åœ¨: {local_model_path}")
            return local_model_path
        
        logger.info(f"âš ï¸ ãƒ¢ãƒ‡ãƒ«ãŒãƒ­ãƒ¼ã‚«ãƒ«ã«è¦‹ã¤ã‹ã‚‰ãªã„ã€R2ã‹ã‚‰ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å¿…è¦: {local_model_path}")
        
        # ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ã‚µãƒ¼ãƒ“ã‚¹åˆæœŸåŒ–
        storage = StorageService()
        
        # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
        with tempfile.NamedTemporaryFile(suffix='.tar.gz', delete=False) as tmp_file:
            tmp_path = tmp_file.name
            
        logger.info(f"ğŸ“¦ ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ä¸­: {settings.KUSHINADA_MODEL_R2_KEY}")
        
        # ãƒ‡ãƒãƒƒã‚°: R2ãƒã‚±ãƒƒãƒˆã®å†…å®¹ã‚’ä¸€è¦§è¡¨ç¤º
        try:
            import boto3
            from botocore.exceptions import ClientError
            
            s3_client = boto3.client(
                's3',
                endpoint_url=settings.R2_ENDPOINT_URL,
                aws_access_key_id=settings.AWS_ACCESS_KEY_ID,
                aws_secret_access_key=settings.AWS_SECRET_ACCESS_KEY
            )
            
            logger.info("ğŸ” R2ãƒã‚±ãƒƒãƒˆã®å†…å®¹ã‚’ç¢ºèªä¸­...")
            response = s3_client.list_objects_v2(Bucket=settings.S3_BUCKET, Prefix='models/')
            
            if 'Contents' in response:
                logger.info(f"ğŸ“ models/ãƒ•ã‚©ãƒ«ãƒ€å†…ã®ãƒ•ã‚¡ã‚¤ãƒ«:")
                for obj in response['Contents']:
                    logger.info(f"  - {obj['Key']} (ã‚µã‚¤ã‚º: {obj['Size']} bytes)")
            else:
                logger.warning("âš ï¸ models/ãƒ•ã‚©ãƒ«ãƒ€ã«ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                
            # ã™ã¹ã¦ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚‚ç¢ºèª
            response_all = s3_client.list_objects_v2(Bucket=settings.S3_BUCKET, MaxKeys=10)
            if 'Contents' in response_all:
                logger.info(f"ğŸ“ ãƒã‚±ãƒƒãƒˆå†…ã®ãƒ•ã‚¡ã‚¤ãƒ«ä¾‹ (æœ€åˆã®10ä»¶):")
                for obj in response_all['Contents']:
                    logger.info(f"  - {obj['Key']}")
                    
        except Exception as list_error:
            logger.error(f"ğŸ” ãƒã‚±ãƒƒãƒˆå†…å®¹ç¢ºèªã‚¨ãƒ©ãƒ¼: {list_error}")
        
        # R2ã‹ã‚‰ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
        storage.download_file(settings.KUSHINADA_MODEL_R2_KEY, tmp_path)
        
        logger.info("ğŸ“‚ ãƒ¢ãƒ‡ãƒ«ã‚’è§£å‡ä¸­...")
        
        # è¦ªãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ
        os.makedirs(os.path.dirname(local_model_path), exist_ok=True)
        
        # tar.gzã‚’è§£å‡
        with tarfile.open(tmp_path, 'r:gz') as tar:
            tar.extractall(os.path.dirname(local_model_path))
        
        # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤
        os.unlink(tmp_path)
        
        logger.info(f"âœ… ãƒ¢ãƒ‡ãƒ«è§£å‡å®Œäº†: {local_model_path}")
        return local_model_path
        
    except Exception as e:
        logger.error(f"âŒ R2ã‹ã‚‰ã®ãƒ¢ãƒ‡ãƒ«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å¤±æ•—: {e}")
        logger.error(f"ğŸ“‹ è©³ç´°: {type(e).__name__}: {str(e)}")
        # R2ã®è¨­å®šç¢ºèªã®ãŸã‚ã®ãƒ‡ãƒãƒƒã‚°æƒ…å ±
        logger.error(f"ğŸ”§ è¨­å®šç¢ºèª: KUSHINADA_MODEL_SOURCE={settings.KUSHINADA_MODEL_SOURCE}")
        logger.error(f"ğŸ”§ è¨­å®šç¢ºèª: KUSHINADA_MODEL_R2_KEY={settings.KUSHINADA_MODEL_R2_KEY}")
        logger.error(f"ğŸ”§ è¨­å®šç¢ºèª: R2_ENDPOINT_URL={getattr(settings, 'R2_ENDPOINT_URL', 'NOT_SET')}")
        raise

class EmotionClassifier:
    """æ„Ÿæƒ…åˆ†é¡å™¨ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, ckpt_path: str = "./ckpt/dev-best.ckpt"):
        self.ckpt_path = ckpt_path
        self.label_map = {
            0: "ä¸­ç«‹ï¼ˆneutralï¼‰",
            1: "å–œã³ï¼ˆhappyï¼‰", 
            2: "æ€’ã‚Šï¼ˆangryï¼‰",
            3: "æ‚²ã—ã¿ï¼ˆsadï¼‰"
        }
        # ãƒ¢ãƒ‡ãƒ«ãƒ‘ã‚¹ã‚’è¨­å®šã‹ã‚‰å–å¾—
        from config import settings
        self.model_source = settings.KUSHINADA_MODEL_SOURCE
        self.model_path = settings.KUSHINADA_LOCAL_PATH if self.model_source == "r2" else "imprt/kushinada-hubert-large"
        self.feature_extractor = None
        self.upstream = None
        self.projector = None
        self.post_net = None
        self._is_initialized = False
        
    def _initialize_models(self):
        """ãƒ¢ãƒ‡ãƒ«ã®åˆæœŸåŒ–ï¼ˆé…å»¶èª­ã¿è¾¼ã¿ï¼‰"""
        if self._is_initialized:
            return
            
        try:
            logger.info("ğŸ¤– Kushinada Hubert Large ãƒ¢ãƒ‡ãƒ«ã‚’åˆæœŸåŒ–ä¸­...")
            
            # Feature Extractor ã¨ Upstream ãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿
            try:
                from config import settings
                
                # ãƒ¢ãƒ‡ãƒ«ã‚½ãƒ¼ã‚¹ã«å¿œã˜ã¦ãƒ‘ã‚¹ã‚’æ±ºå®šï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ä»˜ãï¼‰
                model_loaded = False
                
                if self.model_source == "r2":
                    try:
                        logger.info("ğŸ“¥ R2ã‹ã‚‰ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ä¸­...")
                        model_path = download_model_from_r2()
                        logger.info(f"âœ… R2ã‹ã‚‰ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å®Œäº†: {model_path}")
                        
                        # ãƒ­ãƒ¼ã‚«ãƒ«ãƒ‘ã‚¹ã‹ã‚‰èª­ã¿è¾¼ã¿
                        self.feature_extractor = AutoFeatureExtractor.from_pretrained(model_path)
                        self.upstream = HubertModel.from_pretrained(model_path).eval()
                        logger.info("âœ… R2ã‹ã‚‰ã®Kushinada Hubertãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿å®Œäº†")
                        model_loaded = True
                        
                    except Exception as r2_error:
                        logger.warning(f"âš ï¸ R2ã‹ã‚‰ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å¤±æ•—: {r2_error}")
                        logger.info("ğŸ”„ Hugging Faceã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ä¸­...")
                
                # R2ãŒå¤±æ•—ã—ãŸå ´åˆã€ã¾ãŸã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§Hugging Faceã‚’ä½¿ç”¨
                if not model_loaded:
                    # Hugging Faceèªè¨¼ãƒˆãƒ¼ã‚¯ãƒ³ã®è¨­å®š
                    token_kwargs = {}
                    if settings.HUGGINGFACE_TOKEN:
                        token_kwargs['token'] = settings.HUGGINGFACE_TOKEN
                        logger.info("ğŸ” Hugging Faceèªè¨¼ãƒˆãƒ¼ã‚¯ãƒ³ã‚’ä½¿ç”¨")
                    
                    # AutoFeatureExtractor ã‚’ä½¿ç”¨
                    self.feature_extractor = AutoFeatureExtractor.from_pretrained(
                        "imprt/kushinada-hubert-large", **token_kwargs
                    )
                    logger.info("âœ… AutoFeatureExtractor èª­ã¿è¾¼ã¿å®Œäº†")
                    
                    # HubertModel ã®èª­ã¿è¾¼ã¿
                    self.upstream = HubertModel.from_pretrained(
                        "imprt/kushinada-hubert-large", **token_kwargs
                    ).eval()
                    logger.info("âœ… Kushinada Hubert ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿å®Œäº†")
                
                self.use_kushinada = True
            except Exception as e:
                logger.warning(f"âš ï¸ Kushinada ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿å¤±æ•—: {e}")
                logger.warning("ğŸ­ ãƒ€ãƒŸãƒ¼ãƒ¢ãƒ‡ãƒ«ã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ä¸­...")
                
                # ãƒ€ãƒŸãƒ¼ãƒ¢ãƒ‡ãƒ«ã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
                try:
                    from kushinada_infer_dummy import DummyEmotionClassifier
                    self._dummy_classifier = DummyEmotionClassifier()
                    self._dummy_classifier._initialize_models()
                    self.use_kushinada = False
                    logger.info("âœ… ãƒ€ãƒŸãƒ¼ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–å®Œäº†ï¼ˆé–‹ç™ºãƒ»ãƒ†ã‚¹ãƒˆç”¨ï¼‰")
                except Exception as dummy_error:
                    logger.error(f"âŒ ãƒ€ãƒŸãƒ¼ãƒ¢ãƒ‡ãƒ«ã‚‚åˆæœŸåŒ–å¤±æ•—: {dummy_error}")
                    raise RuntimeError("ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–ã«å®Œå…¨ã«å¤±æ•—ã—ã¾ã—ãŸ")
            
            logger.info("âœ… Upstream ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿å®Œäº†")
            
            # ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã®å­˜åœ¨ç¢ºèª
            if not os.path.exists(self.ckpt_path):
                raise FileNotFoundError(f"ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {self.ckpt_path}")
            
            # Downstream ãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿
            logger.info(f"ğŸ“¦ ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‚’èª­ã¿è¾¼ã¿ä¸­: {self.ckpt_path}")
            ckpt = torch.load(self.ckpt_path, map_location="cpu", weights_only=False)["Downstream"]
            
            # Projector ãƒ¬ã‚¤ãƒ¤ãƒ¼ã®åˆæœŸåŒ–
            projector_weight_shape = ckpt["projector.weight"].shape
            self.projector = torch.nn.Linear(projector_weight_shape[1], projector_weight_shape[0])
            self.projector.load_state_dict({
                "weight": ckpt["projector.weight"],
                "bias": ckpt["projector.bias"]
            })
            self.projector.eval()
            logger.info("âœ… Projector ãƒ¬ã‚¤ãƒ¤ãƒ¼åˆæœŸåŒ–å®Œäº†")
            
            # Post-net ãƒ¬ã‚¤ãƒ¤ãƒ¼ã®åˆæœŸåŒ–
            post_net_weight_shape = ckpt["model.post_net.linear.weight"].shape
            self.post_net = torch.nn.Linear(post_net_weight_shape[1], post_net_weight_shape[0])
            self.post_net.load_state_dict({
                "weight": ckpt["model.post_net.linear.weight"],
                "bias": ckpt["model.post_net.linear.bias"]
            })
            self.post_net.eval()
            logger.info("âœ… Post-net ãƒ¬ã‚¤ãƒ¤ãƒ¼åˆæœŸåŒ–å®Œäº†")
            
            self._is_initialized = True
            logger.info("ğŸ‰ æ„Ÿæƒ…åˆ†é¡å™¨ã®åˆæœŸåŒ–ãŒå®Œäº†ã—ã¾ã—ãŸ")
            
        except Exception as e:
            logger.error(f"âŒ ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")
            raise
    
    def classify_emotion(self, wav_path: str) -> Tuple[str, int, torch.Tensor]:
        """
        éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰æ„Ÿæƒ…ã‚’åˆ†é¡ã™ã‚‹
        
        Args:
            wav_path: WAVãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
            
        Returns:
            Tuple[æ„Ÿæƒ…ãƒ©ãƒ™ãƒ«, äºˆæ¸¬ã‚¯ãƒ©ã‚¹ID, ãƒ­ã‚¸ãƒƒãƒˆ]
        """
        # é…å»¶åˆæœŸåŒ–ï¼šå®Ÿéš›ã«æ¨è«–ãŒå¿…è¦ã«ãªã£ãŸæ™‚ã«ãƒ¢ãƒ‡ãƒ«ã‚’åˆæœŸåŒ–
        if not self._is_initialized:
            logger.info("ğŸš€ åˆå›æ¨è«–å®Ÿè¡Œ - ãƒ¢ãƒ‡ãƒ«ã‚’åˆæœŸåŒ–ä¸­...")
            self._initialize_models()
        
        # ãƒ€ãƒŸãƒ¼ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã™ã‚‹å ´åˆ
        if hasattr(self, '_dummy_classifier') and not self.use_kushinada:
            logger.info("ğŸ­ ãƒ€ãƒŸãƒ¼ãƒ¢ãƒ‡ãƒ«ã§æ¨è«–å®Ÿè¡Œ")
            return self._dummy_classifier.classify_emotion(wav_path)
        
        try:
            logger.info(f"ğŸµ éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡¦ç†ä¸­: {wav_path}")
            
            # soundfile ã‚’ä½¿ç”¨ã—ã¦éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿
            audio_array, sr = sf.read(wav_path)
            logger.info(f"ğŸ“Š èª­ã¿è¾¼ã¿å®Œäº† - ã‚µãƒ³ãƒ—ãƒ«ãƒ¬ãƒ¼ãƒˆ: {sr}Hz, å½¢çŠ¶: {audio_array.shape}")
            
            # AutoFeatureExtractor ã‚’ä½¿ç”¨ã—ã¦å‰å‡¦ç†
            logger.info("ğŸ”„ AutoFeatureExtractor ã«ã‚ˆã‚‹å‰å‡¦ç†ä¸­...")
            inputs = self.feature_extractor(
                audio_array, 
                sampling_rate=sr, 
                return_tensors="pt",
                padding=True
            )
            
            logger.info(f"âœ… å‰å‡¦ç†å®Œäº† - å…¥åŠ›å½¢çŠ¶: {inputs.input_values.shape}")
            
            # æ¨è«–å®Ÿè¡Œ
            with torch.no_grad():
                # ç‰¹å¾´æŠ½å‡ºï¼ˆUpstreamï¼‰
                logger.info("ğŸ§  ç‰¹å¾´æŠ½å‡ºä¸­...")
                features = self.upstream(inputs.input_values).last_hidden_state.mean(dim=1)
                logger.info(f"ğŸ“ˆ ç‰¹å¾´æŠ½å‡ºå®Œäº† - ç‰¹å¾´é‡å½¢çŠ¶: {features.shape}")
                
                # Projectoré€šé
                x = self.projector(features)
                logger.info(f"ğŸ”„ Projectoré€šéå®Œäº† - å½¢çŠ¶: {x.shape}")
                
                # Post-neté€šéï¼ˆæœ€çµ‚ãƒ­ã‚¸ãƒƒãƒˆï¼‰
                logits = self.post_net(x)
                logger.info(f"ğŸ¯ Post-neté€šéå®Œäº† - ãƒ­ã‚¸ãƒƒãƒˆå½¢çŠ¶: {logits.shape}")
                
                # äºˆæ¸¬ã‚¯ãƒ©ã‚¹
                pred_class = torch.argmax(logits, dim=-1).item()
                emotion_label = self.label_map.get(pred_class, "ä¸æ˜")
                
                logger.info(f"ğŸ­ æ¨è«–çµæœ: {emotion_label} (ã‚¯ãƒ©ã‚¹{pred_class})")
                
                return emotion_label, pred_class, logits
                
        except Exception as e:
            logger.error(f"âŒ æ„Ÿæƒ…åˆ†é¡ã‚¨ãƒ©ãƒ¼: {e}")
            raise

def calc_score_softmax_based(logits: torch.Tensor, target_label: int) -> int:
    """
    ãƒ­ã‚¸ãƒƒãƒˆ x ã‹ã‚‰ softmax ã‚’è¨ˆç®—ã—ã€target_label ã«å¯¾å¿œã™ã‚‹ç¢ºç‡ã‚’ 100ç‚¹æº€ç‚¹ã§è¿”ã™
    
    Args:
        logits: ãƒ¢ãƒ‡ãƒ«å‡ºåŠ›ã®ãƒ­ã‚¸ãƒƒãƒˆ [batch_size, num_classes]
        target_label: ç›®æ¨™æ„Ÿæƒ…ã®ã‚¯ãƒ©ã‚¹ID (0-3)
        
    Returns:
        100ç‚¹æº€ç‚¹ã®ã‚¹ã‚³ã‚¢
    """
    try:
        # ã‚½ãƒ•ãƒˆãƒãƒƒã‚¯ã‚¹ã§ç¢ºç‡ã«å¤‰æ›
        probs = torch.softmax(logits, dim=-1)
        
        # ç›®æ¨™ãƒ©ãƒ™ãƒ«ã®ç¢ºç‡ã‚’å–å¾—
        target_prob = probs[0][target_label].item()
        
        # 100ç‚¹æº€ç‚¹ã§ã‚¹ã‚³ã‚¢åŒ–
        score = round(target_prob * 100)
        
        logger.info(f"ğŸ“Š ã‚¹ã‚³ã‚¢è¨ˆç®—: ç›®æ¨™ã‚¯ãƒ©ã‚¹{target_label}ã®ç¢ºç‡={target_prob:.4f} â†’ {score}ç‚¹")
        
        return score
        
    except Exception as e:
        logger.error(f"âŒ ã‚¹ã‚³ã‚¢è¨ˆç®—ã‚¨ãƒ©ãƒ¼: {e}")
        return 0

# ã‚°ãƒ­ãƒ¼ãƒãƒ«ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ï¼ˆã‚·ãƒ³ã‚°ãƒ«ãƒˆãƒ³ï¼‰
_classifier = None

def get_emotion_classifier() -> EmotionClassifier:
    """æ„Ÿæƒ…åˆ†é¡å™¨ã®ã‚·ãƒ³ã‚°ãƒ«ãƒˆãƒ³ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’å–å¾—ï¼ˆé…å»¶åˆæœŸåŒ–ï¼‰"""
    global _classifier
    if _classifier is None:
        _classifier = EmotionClassifier()
        # åˆæœŸåŒ–ã¯å®Ÿéš›ã«æ¨è«–ãŒå¿…è¦ã«ãªã£ãŸæ™‚ã¾ã§é…å»¶
    return _classifier

def classify_emotion_with_score(wav_path: str, target_emotion: int) -> dict:
    """
    éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰æ„Ÿæƒ…ã‚’åˆ†é¡ã—ã€ã‚¹ã‚³ã‚¢ã‚‚è¨ˆç®—ã™ã‚‹
    
    Args:
        wav_path: WAVãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
        target_emotion: ç›®æ¨™æ„Ÿæƒ…ã®ã‚¯ãƒ©ã‚¹ID (0-3)
        
    Returns:
        {
            "emotion": "æ„Ÿæƒ…ãƒ©ãƒ™ãƒ«",
            "predicted_class": äºˆæ¸¬ã‚¯ãƒ©ã‚¹ID,
            "target_class": ç›®æ¨™ã‚¯ãƒ©ã‚¹ID,
            "score": ã‚¹ã‚³ã‚¢(0-100),
            "confidence": äºˆæ¸¬ã‚¯ãƒ©ã‚¹ã®ç¢ºä¿¡åº¦,
            "is_correct": æ­£è§£ã‹ã©ã†ã‹
        }
    """
    try:
        classifier = get_emotion_classifier()
        
        # æ„Ÿæƒ…åˆ†é¡å®Ÿè¡Œ
        emotion_label, pred_class, logits = classifier.classify_emotion(wav_path)
        
        # ã‚¹ã‚³ã‚¢è¨ˆç®—
        score = calc_score_softmax_based(logits, target_emotion)
        
        # äºˆæ¸¬ã‚¯ãƒ©ã‚¹ã®ç¢ºä¿¡åº¦ã‚‚è¨ˆç®—
        probs = torch.softmax(logits, dim=-1)
        confidence = probs[0][pred_class].item()
        
        # æ­£è§£åˆ¤å®š
        is_correct = (pred_class == target_emotion)
        
        result = {
            "emotion": emotion_label,
            "predicted_class": pred_class,
            "target_class": target_emotion,
            "score": score,
            "confidence": round(confidence * 100, 2),
            "is_correct": is_correct
        }
        
        logger.info(f"ğŸ¯ æœ€çµ‚çµæœ: {result}")
        return result
        
    except Exception as e:
        logger.error(f"âŒ åˆ†é¡å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
        raise